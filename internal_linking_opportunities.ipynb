{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34059151",
   "metadata": {},
   "source": [
    "# Internal Linking Opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd482d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Author: Ruben Remy.<br />\n",
    "LinkedIn: https://www.linkedin.com/in/rubenremy/<br />\n",
    "Website: https://conversem.com/<br />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1738dd29",
   "metadata": {},
   "source": [
    " Make sure you have a crawl with content scraped of every page, cleaned of HTML, called \"crawl.csv\". We asume Sitebulb but you can use Screaming Frog or any other solution too.\n",
    " We need the headers:\n",
    " URL,content.\n",
    " \n",
    " Then the second file you need is a qualitative list of assigned keywords to landing pages with headers:\n",
    " Keyword, URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f988ca",
   "metadata": {},
   "source": [
    "Check if your csv files are in the same folder as this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3ea795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# List files in the current directory\n",
    "files_in_current_directory = os.listdir(current_directory)\n",
    "\n",
    "# Print the list of files\n",
    "print(\"Files in the current directory:\")\n",
    "for file in files_in_current_directory:\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc2c222",
   "metadata": {},
   "source": [
    "Import the csv files into the 2 dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89dcd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files into pandas dataframes\n",
    "crawl_df = pd.read_csv('crawl.csv')\n",
    "keyword_df = pd.read_csv('kw-targeting.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22163147",
   "metadata": {},
   "source": [
    "The logic to exclude checking for internal link opportunities on the to be linked page itself (crawl_url cannot be target_url), then if the search term is present in content of a crawl_url, we append that search term and the target url to the crawl url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a001ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over each row in crawl_df\n",
    "for index, row in crawl_df.iterrows():\n",
    "    crawl_df = row[\"URL\"]\n",
    "    content = row[\"content\"]\n",
    "    \n",
    "    # Iterate over each row in keyword_df\n",
    "    for index_keyword, row_keyword in keyword_df.iterrows():\n",
    "        target_url = row_keyword[\"URL\"]\n",
    "        \n",
    "        # Check if crawl_url does not match the URL\n",
    "        if crawl_url != target_url:\n",
    "            search_term = row_keyword[\"Keyword\"]\n",
    "            \n",
    "            # Check if the search term is present in the content\n",
    "            if search_term in content:\n",
    "                results.append((crawl_url, search_term, target_url))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f2e73",
   "metadata": {},
   "source": [
    "Export results to Excel. There you can make a view pivot tables to finish your results with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf68e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results list to a dataframe\n",
    "result_df = pd.DataFrame(results, columns=[\"crawl_url\", \"Keyword\", \"target_url\"])\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "result_df.to_excel(\"internal_linking_opportunities.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
